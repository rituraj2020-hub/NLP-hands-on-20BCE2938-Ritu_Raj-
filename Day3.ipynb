{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.gutenberg.org/files/98/98-0.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = request.urlopen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = response.read().decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(raw)\n",
    "#BeautifulSoup useful for extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffThe', 'Project', 'Gutenberg', 'eBook', 'of', 'A', 'Tale', 'of', 'Two', 'Cities', ',', 'by', 'Charles', 'Dickens', 'This', 'eBook', 'is', 'for', 'the', 'use']\n"
     ]
    }
   ],
   "source": [
    "print(tokens[:20])\n",
    "#PreProcess - RE to clean HTML tags or unnecessary char sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walk\n",
      "happi\n",
      "cacti\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer \n",
    "#sensitive to suffixes\n",
    "porter = PorterStemmer()\n",
    "print(porter.stem('walking'))\n",
    "print(porter.stem('happy'))\n",
    "print(porter.stem('cacti'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy\n",
      "walk\n",
      "cact\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import LancasterStemmer\n",
    "lancaster = LancasterStemmer()\n",
    "print(lancaster.stem('happiness'))\n",
    "print(lancaster.stem('walking'))\n",
    "print(lancaster.stem('cacti'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walk\n",
      "cunn\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import RegexpStemmer\n",
    "regex = RegexpStemmer('ing')\n",
    "print(regex.stem('walking'))\n",
    "print(regex.stem('cunning')) #run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detest\n",
      "avoir\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "snow = SnowballStemmer('french')\n",
    "print(snow.stem('detester'))\n",
    "#one case where it doesnt work\n",
    "print(snow.stem('avoir'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thi\n",
      "ebook\n",
      "is\n",
      "for\n",
      "the\n",
      "us\n",
      "of\n",
      "anyon\n",
      "anywh\n",
      "in\n",
      "the\n",
      "unit\n",
      "stat\n",
      "and\n",
      "most\n",
      "oth\n",
      "part\n",
      "of\n",
      "the\n",
      "world\n",
      "at\n",
      "no\n",
      "cost\n",
      "and\n",
      "with\n",
      "almost\n",
      "no\n",
      "restrict\n",
      "whatsoev\n",
      ".\n",
      "you\n",
      "may\n",
      "cop\n",
      "it\n",
      ",\n",
      "giv\n",
      "it\n",
      "away\n",
      "or\n",
      "re-us\n",
      "it\n",
      "und\n",
      "the\n",
      "term\n",
      "of\n",
      "the\n",
      "project\n",
      "gutenberg\n",
      "licens\n",
      "includ\n",
      "with\n",
      "thi\n",
      "ebook\n",
      "or\n",
      "onlin\n",
      "at\n",
      "www.gutenberg.org\n",
      ".\n",
      "if\n",
      "you\n",
      "ar\n",
      "not\n",
      "loc\n",
      "in\n",
      "the\n",
      "unit\n",
      "stat\n",
      ",\n",
      "you\n",
      "wil\n",
      "hav\n",
      "to\n",
      "check\n",
      "the\n",
      "law\n",
      "of\n",
      "the\n",
      "country\n",
      "wher\n",
      "you\n",
      "ar\n",
      "loc\n",
      "bef\n",
      "us\n",
      "thi\n",
      "ebook\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "text= 'This eBook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or online at www.gutenberg.org. If you are not located in the United States, you will have to check the laws of the country where you are located before using this eBook.'\n",
    "t1 = word_tokenize(text)\n",
    "for word in t1:\n",
    "    print(lancaster.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ee2ff7779dc8f7ade0334fb0d4569cc8f860fafa4ae25cf1bfbc35cee63df49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
