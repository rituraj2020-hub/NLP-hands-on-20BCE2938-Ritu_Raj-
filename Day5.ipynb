{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A DET DT\n",
      "Note NOUN NN\n",
      "about ADP IN\n",
      "Witches PROPN NNP\n",
      ". PUNCT .\n",
      "In ADP IN\n",
      "fairy NOUN NN\n",
      "- PUNCT HYPH\n",
      "tales NOUN NNS\n",
      ", PUNCT ,\n",
      "witches NOUN NNS\n",
      "always ADV RB\n",
      "wear VERB VBP\n",
      "silly ADJ JJ\n",
      "black ADJ JJ\n",
      "hats NOUN NNS\n",
      "and CCONJ CC\n",
      "black ADJ JJ\n",
      "cloaks NOUN NNS\n",
      ", PUNCT ,\n",
      "and CCONJ CC\n",
      "they PRON PRP\n",
      "ride VERB VBP\n",
      "on ADP IN\n",
      "broomsticks NOUN NNS\n",
      ". PUNCT .\n",
      "But CCONJ CC\n",
      "this PRON DT\n",
      "is AUX VBZ\n",
      "not PART RB\n",
      "a DET DT\n",
      "fairy NOUN NN\n",
      "- PUNCT HYPH\n",
      "tale NOUN NN\n",
      ". PUNCT .\n",
      "This PRON DT\n",
      "is AUX VBZ\n",
      "about ADP IN\n",
      "REAL ADJ JJ\n",
      "WITCHES PROPN NNP\n",
      ". PUNCT .\n",
      "The DET DT\n",
      "most ADV RBS\n",
      "important ADJ JJ\n",
      "thing NOUN NN\n",
      "you PRON PRP\n",
      "should AUX MD\n",
      "know VERB VB\n",
      "about ADP IN\n",
      "REAL PROPN NNP\n",
      "WITCHES PROPN NNP\n",
      "is AUX VBZ\n",
      "this PRON DT\n",
      ". PUNCT .\n",
      "Listen VERB VB\n",
      "very ADV RB\n",
      "carefully ADV RB\n",
      ". PUNCT .\n",
      "Never ADV RB\n",
      "forget VERB VB\n",
      "what PRON WP\n",
      "is AUX VBZ\n",
      "coming VERB VBG\n",
      "next ADV RB\n",
      ". PUNCT .\n",
      "REAL ADJ JJ\n",
      "WITCHES PROPN NNP\n",
      "dress NOUN NN\n",
      "in ADP IN\n",
      "ordinary ADJ JJ\n",
      "clothes NOUN NNS\n",
      "and CCONJ CC\n",
      "look VERB VB\n",
      "very ADV RB\n",
      "much ADV RB\n",
      "like ADP IN\n",
      "ordinary ADJ JJ\n",
      "women NOUN NNS\n",
      ". PUNCT .\n",
      "They PRON PRP\n",
      "live VERB VBP\n",
      "in ADP IN\n",
      "ordinary ADJ JJ\n",
      "houses NOUN NNS\n",
      "and CCONJ CC\n",
      "they PRON PRP\n",
      "work VERB VBP\n",
      "in ADP IN\n",
      "ORDINARY PROPN NNP\n",
      "JOBS PROPN NNP\n",
      ". PUNCT .\n",
      "That PRON DT\n",
      "is AUX VBZ\n",
      "why SCONJ WRB\n",
      "they PRON PRP\n",
      "are AUX VBP\n",
      "so ADV RB\n",
      "hard ADJ JJ\n",
      "to PART TO\n",
      "catch VERB VB\n",
      ". PUNCT .\n",
      "A DET DT\n",
      "REAL ADJ JJ\n",
      "WITCH PROPN NNP\n",
      "hates VERB VBZ\n",
      "children NOUN NNS\n",
      "with ADP IN\n",
      "a DET DT\n",
      "red ADJ JJ\n",
      "- PUNCT HYPH\n",
      "hot ADJ JJ\n",
      "sizz ADJ JJ\n",
      "- PUNCT HYPH\n",
      "ling NOUN NN\n",
      "hatred NOUN NN\n",
      "that PRON WDT\n",
      "is AUX VBZ\n",
      "more ADV RBR\n",
      "sizzling ADJ JJ\n",
      "and CCONJ CC\n",
      "red ADJ JJ\n",
      "- PUNCT HYPH\n",
      "hot ADJ JJ\n",
      "than SCONJ IN\n",
      "anyhatred VERB VBD\n",
      "you PRON PRP\n",
      "could AUX MD\n",
      "possibly ADV RB\n",
      "imagine VERB VB\n",
      ". PUNCT .\n",
      "A DET DT\n",
      "REAL PROPN NNP\n",
      "WITCH PROPN NNP\n",
      "spends VERB VBZ\n",
      "all DET DT\n",
      "her PRON PRP$\n",
      "time NOUN NN\n",
      "plotting VERB VBG\n",
      "to PART TO\n",
      "get AUX VB\n",
      "rid VERB VBN\n",
      "of ADP IN\n",
      "the DET DT\n",
      "children NOUN NNS\n",
      "in ADP IN\n",
      "her PRON PRP$\n",
      "particular ADJ JJ\n",
      "territory NOUN NN\n",
      ". PUNCT .\n",
      "Her PRON PRP$\n",
      "passion NOUN NN\n",
      "is AUX VBZ\n",
      "to PART TO\n",
      "do VERB VB\n",
      "away ADV RB\n",
      "with ADP IN\n",
      "them PRON PRP\n",
      ", PUNCT ,\n",
      "one NUM CD\n",
      "by ADP IN\n",
      "one NUM CD\n",
      ". PUNCT .\n",
      "It PRON PRP\n",
      "is AUX VBZ\n",
      "all PRON DT\n",
      "she PRON PRP\n",
      "thinks VERB VBZ\n",
      "about ADP IN\n",
      "the DET DT\n",
      "whole ADJ JJ\n",
      "day NOUN NN\n",
      "long ADV RB\n",
      ". PUNCT .\n",
      "Even ADV RB\n",
      "if SCONJ IN\n",
      "she PRON PRP\n",
      "is AUX VBZ\n",
      "working VERB VBG\n",
      "as ADP IN\n",
      "a DET DT\n",
      "cashier NOUN NN\n",
      "in ADP IN\n",
      "a DET DT\n",
      "supermarket NOUN NN\n",
      "or CCONJ CC\n",
      "typing VERB VBG\n",
      "letters NOUN NNS\n",
      "for ADP IN\n",
      "a DET DT\n",
      "businessman NOUN NN\n",
      "or CCONJ CC\n",
      "driving VERB VBG\n",
      "round NOUN NN\n",
      "in ADP IN\n",
      "a DET DT\n",
      "fancy ADJ JJ\n",
      "car NOUN NN\n",
      "( PUNCT -LRB-\n",
      "and CCONJ CC\n",
      "she PRON PRP\n",
      "could AUX MD\n",
      "be AUX VB\n",
      "doing VERB VBG\n",
      "any PRON DT\n",
      "of ADP IN\n",
      "these DET DT\n",
      "things NOUN NNS\n",
      ") PUNCT -RRB-\n",
      ", PUNCT ,\n",
      "her PRON PRP$\n",
      "mind NOUN NN\n",
      "will AUX MD\n",
      "always ADV RB\n",
      "be AUX VB\n",
      "plotting VERB VBG\n",
      "and CCONJ CC\n",
      "scheming VERB VBG\n",
      "and CCONJ CC\n",
      "churning VERB VBG\n",
      "and CCONJ CC\n",
      "burning NOUN NN\n",
      "and CCONJ CC\n",
      "whiz NOUN NN\n",
      "- PUNCT HYPH\n",
      "zing VERB VBG\n",
      "and CCONJ CC\n",
      "phizzing NOUN NN\n",
      "with ADP IN\n",
      "murderous ADJ JJ\n",
      "bloodthirsty ADJ JJ\n",
      "thoughts NOUN NNS\n",
      ". PUNCT .\n",
      "' PUNCT ``\n",
      "Which DET WDT\n",
      "child NOUN NN\n",
      ", PUNCT ,\n",
      "' PUNCT ''\n",
      "she PRON PRP\n",
      "says VERB VBZ\n",
      "to ADP IN\n",
      "herself PRON PRP\n",
      "all DET DT\n",
      "day NOUN NN\n",
      "long ADV RB\n",
      ", PUNCT ,\n",
      "' PUNCT ``\n",
      "exactly ADV RB\n",
      "which DET WDT\n",
      "child NOUN NN\n",
      "shall AUX MD\n",
      "I PRON PRP\n",
      "choose VERB VB\n",
      "for ADP IN\n",
      "my PRON PRP$\n",
      "next ADJ JJ\n",
      "squelching NOUN NN\n",
      "? PUNCT .\n",
      "' PUNCT ''\n",
      "A DET DT\n",
      "REAL PROPN NNP\n",
      "WITCH PROPN NNP\n",
      "gets VERB VBZ\n",
      "the DET DT\n",
      "same ADJ JJ\n",
      "pleasure NOUN NN\n",
      "from ADP IN\n",
      "squel PROPN NNP\n",
      "- PUNCT HYPH\n",
      "ching PROPN NNP\n",
      "a DET DT\n",
      "child NOUN NN\n",
      "asyou PRON PRP\n",
      "get VERB VBP\n",
      "from ADP IN\n",
      "eating VERB VBG\n",
      "a DET DT\n",
      "plateful NOUN NN\n",
      "of ADP IN\n",
      "strawberries NOUN NNS\n",
      "and CCONJ CC\n",
      "thick ADJ JJ\n",
      "cream NOUN NN\n",
      ". PUNCT .\n",
      "She PRON PRP\n",
      "reckons VERB VBZ\n",
      "on ADP IN\n",
      "doing VERB VBG\n",
      "away ADV RB\n",
      "with ADP IN\n",
      "one NUM CD\n",
      "child NOUN NN\n",
      "a DET DT\n",
      "week NOUN NN\n",
      ". PUNCT .\n",
      "Anything PRON NN\n",
      "less ADJ JJR\n",
      "than ADP IN\n",
      "that PRON DT\n",
      "and CCONJ CC\n",
      "she PRON PRP\n",
      "becomes VERB VBZ\n",
      "grumpy ADJ JJ\n",
      ". PUNCT .\n",
      "One NUM CD\n",
      "child NOUN NN\n",
      "a DET DT\n",
      "week NOUN NN\n",
      "is AUX VBZ\n",
      "fifty NUM CD\n",
      "- PUNCT HYPH\n",
      "two NUM CD\n",
      "a DET DT\n",
      "year NOUN NN\n",
      ". PUNCT .\n"
     ]
    }
   ],
   "source": [
    "example =\"A Note about Witches. In fairy-tales, witches always wear silly black hats and black cloaks, and they ride on broomsticks. But this is not a fairy-tale. This is about REAL WITCHES. The most important thing you should know about REAL WITCHES is this. Listen very carefully. Never forget what is coming next. REAL WITCHES dress in ordinary clothes and look very much like ordinary women. They live in ordinary houses and they work in ORDINARY JOBS. That is why they are so hard to catch. A REAL WITCH hates children with a red-hot sizz-ling hatred that is more sizzling and red-hot than anyhatred you could possibly imagine. A REAL WITCH spends all her time plotting to get rid of the children in her particular territory. Her passion is to do away with them, one by one. It is all she thinks about the whole day long. Even if she is working as a cashier in a supermarket or typing letters for a businessman or driving round in a fancy car (and she could be doing any of these things), her mind will always be plotting and scheming and churning and burning and whiz-zing and phizzing with murderous bloodthirsty thoughts. 'Which child,' she says to herself all day long, 'exactly which child shall I choose for my next squelching?' A REAL WITCH gets the same pleasure from squel-ching a child asyou get from eating a plateful of strawberries and thick cream. She reckons on doing away with one child a week. Anything less than that and she becomes grumpy. One child a week is fifty-two a year.\"\n",
    "doc = m(example)\n",
    "\n",
    "#for ent in doc.ents:\n",
    "    #print(\"{0} ... {1}\".format(ent.text,ent.labels))\n",
    "\n",
    "for token in doc:  \n",
    "    \n",
    "    # Print each token\n",
    "    print(token, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Witches PERSON\n",
      "one CARDINAL\n",
      "all day long DATE\n",
      "one CARDINAL\n",
      "One CARDINAL\n",
      "fifty-two CARDINAL\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "\n",
    "    # Print the named entity and its label\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentimental Analysis of IDMB reviews\n",
    "#imoprt libraries \n",
    "import pandas as pd\n",
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\RITU\n",
      "[nltk_data]     RAJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\RITU\n",
      "[nltk_data]     RAJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Preprocess the text data:\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove HTML tags and non-alphanumeric characters\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    text = re.sub('[^a-zA-Z0-9]', ' ', text)\n",
    "    \n",
    "    # Convert to lowercase and tokenize\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove stop words and lemmatize tokens\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Join tokens into a string\n",
    "    return ' '.join(tokens)\n",
    "    \n",
    "df['review'] = df['review'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and testing sets:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize the text data using the tf-idf vectorizer:\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train a classifier (e.g., logistic regression) on the vectorized data:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8958\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the classifier on the testing set:\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the trained model using the pickle module in Python:\n",
    "import pickle\n",
    "\n",
    "# Save the vectorizer and classifier\n",
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump((vectorizer, clf), file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved vectorizer and classifier\n",
    "with open('model.pkl', 'rb') as file:\n",
    "    vectorizer, clf = pickle.load(file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
